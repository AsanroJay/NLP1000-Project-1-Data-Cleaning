# NLP1000-Project-1-Data-Cleaning - Creating Parallel Corpus for Bible Text

## Steps Taken

### Scraping
I explored **bible.com** and **biblegateway.com** to figure out how to systematically scrape chapters and verses.  

- **bible.com** URLs follow the pattern:  
  `https://www.bible.com/bible/{version}/{book}.{chapter}.{translation}`  
- **biblegateway.com** URLs follow the pattern:  
  `https://www.biblegateway.com/passage/?search={book}+{chapter}&version={translation}`  

I built two scrapers (`bible.com_scraper.py` and `biblegateway_scraper.py`) using **BeautifulSoup** to extract the raw text, given the version, book, chapter, and translation.

---

### Cleaning
For cleaning, I used [regex101](https://regex101.com) to test patterns interactively before applying them to the raw text. A detailed list of the regex rules and manual fixes can be found in **Steps.xlsx**.

Initially, I wrote many regex patterns to handle noisy text (e.g., references like  
`# Gen. 12:7; Gen. 26:3; Gen. 28:13.` or `2:22 GERSOM:`).  

Later, I realized much of this noise came from fact bubbles in bible.com (marked with `#`). By tweaking the scraper to skip those HTML elements, I reduced the need for heavy regex cleanup. Now only minimal cleaning is required.

---

### Code Structure
- **`utils.py`** – contains helper functions for processing, cleaning, and combining text.  
- **`bible.com_scraper.py` / `biblegateway_scraper.py`** – dedicated scrapers for each site.  
- **Jupyter notebooks** – used for experimenting, documenting, and running cleaning/processing steps in a structured way.  

---

### Notes
- Cleaning combines **regex-based rules** with **manual fixes** when necessary.  
- Output is structured CSVs per book and language.  
- Parallel corpora are later generated by aligning verses across languages.  
